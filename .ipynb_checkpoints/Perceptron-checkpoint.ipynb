{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# CSE 151 PA3\n",
    "Zheng Zeng A14679117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Importing package and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%% \n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "train_data = np.genfromtxt(dtype = 'float', fname='pa3train.txt', delimiter=' ')\n",
    "testing_data = np.genfromtxt(dtype = 'float', fname='pa3test.txt', delimiter=' ')\n",
    "dictionary = np.genfromtxt(dtype = 'str', fname='pa3dictionary.txt', autostrip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Firstly, implementing the perceptron training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def perceptron(training, weight):\n",
    "    ## initially, set w to weight\n",
    "    w = []\n",
    "    c = []\n",
    "    m = 0\n",
    "    m_cnt = 1\n",
    "    w.append(weight)\n",
    "    for i in range(0, len(training)):\n",
    "        vi = training[i]\n",
    "        if condition(vi, w[m]):\n",
    "            xi = vi[:len(vi)-1]\n",
    "            yi = vi[len(vi)-1]\n",
    "            if yi == 1.0:\n",
    "                yi = -1\n",
    "            else:\n",
    "                yi = 1\n",
    "            wi = np.add(w[m], np.multiply(xi,yi))\n",
    "            w.append(wi)\n",
    "            c.append(m_cnt)\n",
    "            m_cnt = 1\n",
    "            m = m+1\n",
    "        else:\n",
    "            m_cnt = m_cnt + 1\n",
    "    return {\"weights\":w, \"counts\":c, \"len\":m}\n",
    "        \n",
    "def condition(data, weight):\n",
    "    x = data[:819]\n",
    "    yi = data[819]\n",
    "    if yi == 1.0:\n",
    "        yi = -1\n",
    "    else:\n",
    "        yi = 1\n",
    "    product = np.dot(weight, x)\n",
    "    return yi * product <= 0\n",
    "    \n",
    "def predict(data, weight):\n",
    "    x = data[:819]\n",
    "    product = np.dot(weight, x)\n",
    "    if product < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def regular_predict(data, perceptron):\n",
    "    last = perceptron['len']\n",
    "    weight = perceptron['weights'][last]\n",
    "    sign = predict(data, weight)\n",
    "    if sign < 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 2.0\n",
    "\n",
    "def vote_predict(data, perceptron):\n",
    "    w = perceptron['weights']\n",
    "    c = perceptron['counts']\n",
    "    length = perceptron['len']\n",
    "    result = 0\n",
    "    for i in range(0, length):\n",
    "        result = result + predict(data, w[i]) * c[i]\n",
    "    if result < 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 2.0\n",
    "    \n",
    "def average_predict(data, perceptron):\n",
    "    w = perceptron['weights']\n",
    "    c = perceptron['counts']\n",
    "    length = perceptron['len']\n",
    "    sum_weights = 0\n",
    "    for i in range(0, length):\n",
    "        sum_weights = sum_weights + c[i] * w[i]\n",
    "    sign = predict(data, sum_weights)\n",
    "    if sign < 0:\n",
    "        return 1.0\n",
    "    else:\n",
    "        return 2.0\n",
    "\n",
    "def error(dataset, perceptron, flag):\n",
    "    err_cnt = 0\n",
    "    for data in dataset:\n",
    "        if flag == \"regular\":\n",
    "            label = regular_predict(data, perceptron)\n",
    "        elif flag == \"vote\":\n",
    "            label = vote_predict(data, perceptron)\n",
    "        elif flag == \"average\":\n",
    "            label = average_predict(data, perceptron)\n",
    "        if label != data[819]:\n",
    "            err_cnt = err_cnt+1\n",
    "    return err_cnt/len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Problem 1\n",
    "Firstly, take out the subset from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## function to get subset\n",
    "def subset(dataset):\n",
    "    train_subset = []\n",
    "    for data in dataset:\n",
    "        if data[len(data)-1] == 1.0 or data[len(data)-1] == 2.0:\n",
    "            train_subset.append(data)\n",
    "    return train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single pass\n",
      "training error\n",
      "{'regular': 0.04128440366972477, 'vote': 0.06697247706422019, 'average': 0.0798165137614679}\n",
      "two passes\n",
      "training error\n",
      "{'regular': 0.04036697247706422, 'vote': 0.04036697247706422, 'average': 0.05412844036697248}\n",
      "testing error\n",
      "{'regular': 0.058355437665782495, 'vote': 0.0610079575596817, 'average': 0.08222811671087533}\n",
      "three passes\n",
      "training error\n",
      "{'regular': 0.02110091743119266, 'vote': 0.030275229357798167, 'average': 0.03761467889908257}\n",
      "testing error\n",
      "{'regular': 0.04509283819628647, 'vote': 0.04509283819628647, 'average': 0.0610079575596817}\n",
      "four passes\n",
      "training error\n",
      "{'regular': 0.01834862385321101, 'vote': 0.026605504587155965, 'average': 0.03394495412844037}\n",
      "testing error\n",
      "{'regular': 0.04774535809018567, 'vote': 0.04509283819628647, 'average': 0.050397877984084884}\n"
     ]
    }
   ],
   "source": [
    "train_subset = subset(train_data)\n",
    "test_subset = subset(testing_data)\n",
    "\n",
    "print(\"single pass\")\n",
    "print(\"training error\")\n",
    "initial_weight = np.zeros(shape=819, dtype='float')\n",
    "single_pass = perceptron(train_subset, initial_weight)\n",
    "single_table = {\"regular\": error(train_subset, single_pass, \"regular\"), \"vote\":error(train_subset, single_pass, \"vote\"), \"average\": error(train_subset, single_pass, \"average\")}\n",
    "print(single_table)\n",
    "\n",
    "train_subset_cpy = copy.deepcopy(train_subset)\n",
    "\n",
    "print(\"two passes\")\n",
    "print(\"training error\")\n",
    "train_subset.extend(train_subset_cpy)\n",
    "two_passes = perceptron(train_subset, initial_weight)\n",
    "two_table = {\"regular\": error(train_subset, two_passes, \"regular\"), \"vote\":error(train_subset, two_passes, \"vote\"), \"average\": error(train_subset, two_passes, \"average\")}\n",
    "print(two_table)\n",
    "print(\"testing error\")\n",
    "two_table = {\"regular\": error(test_subset, two_passes, \"regular\"), \"vote\":error(test_subset, two_passes, \"vote\"), \"average\": error(test_subset, two_passes, \"average\")}\n",
    "print(two_table)\n",
    "\n",
    "print(\"three passes\")\n",
    "print(\"training error\")\n",
    "#initial_weight = two_passes[\"weights\"][two_passes[\"len\"]]\n",
    "train_subset.extend(train_subset_cpy)\n",
    "three_passes = perceptron(train_subset, initial_weight)\n",
    "three_table = {\"regular\": error(train_subset, three_passes, \"regular\"), \"vote\":error(train_subset, three_passes, \"vote\"), \"average\": error(train_subset, three_passes, \"average\")}\n",
    "print(three_table)\n",
    "print(\"testing error\")\n",
    "three_table = {\"regular\": error(test_subset, three_passes, \"regular\"), \"vote\":error(test_subset, three_passes, \"vote\"), \"average\": error(test_subset, three_passes, \"average\")}\n",
    "print(three_table)\n",
    "\n",
    "print(\"four passes\")\n",
    "print(\"training error\")\n",
    "#initial_weight = three_passes[\"weights\"][three_passes[\"len\"]]\n",
    "train_subset.extend(train_subset_cpy)\n",
    "four_passes = perceptron(train_subset, initial_weight)\n",
    "four_table = {\"regular\": error(train_subset, four_passes, \"regular\"), \"vote\":error(train_subset, four_passes, \"vote\"), \"average\": error(train_subset, four_passes, \"average\")}\n",
    "print(four_table)\n",
    "print(\"testing error\")\n",
    "four_table = {\"regular\": error(test_subset, four_passes, \"regular\"), \"vote\":error(test_subset, four_passes, \"vote\"), \"average\": error(test_subset, four_passes, \"average\")}\n",
    "print(four_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the corresponding words:\n",
      "top three highest (descending)\n",
      "{'1st': 'file', '2nd': 'program', '3rd': 'line'}\n",
      "top three lowest (ascending)\n",
      "{'1st': 'he', '2nd': 'team', '3rd': 'game'}\n"
     ]
    }
   ],
   "source": [
    "w = three_passes['weights']\n",
    "c = three_passes['counts']\n",
    "length = three_passes['len']\n",
    "#calculating the average weight\n",
    "wavg = 0\n",
    "for i in range(0, length):\n",
    "    wavg = wavg + c[i] * w[i]\n",
    "#finding the top three highest\n",
    "top3 = []\n",
    "for i in range(0, len(wavg)):\n",
    "    curr = []\n",
    "    if len(top3) != 3:\n",
    "        curr.append(wavg[i])\n",
    "        curr.append(i)\n",
    "        top3.append(curr)\n",
    "    else:\n",
    "        top3 = sorted(top3, key=lambda x:x[0], reverse=False)\n",
    "        if wavg[i] < top3[2][0]:\n",
    "            top3[2][0] = wavg[i]\n",
    "            top3[2][1] = i\n",
    "top3 = sorted(top3, key=lambda x:x[0], reverse=False)\n",
    "low3 = []\n",
    "for i in range(0, len(wavg)):\n",
    "    curr = []\n",
    "    if len(low3) != 3:\n",
    "        curr.append(wavg[i])\n",
    "        curr.append(i)\n",
    "        low3.append(curr)\n",
    "    else:\n",
    "        low3 = sorted(low3, key=lambda x:x[0], reverse=True)\n",
    "        if wavg[i] > low3[2][0]:\n",
    "            low3[2][0] = wavg[i]\n",
    "            low3[2][1] = i\n",
    "low3 = sorted(low3, key = lambda x:x[0], reverse=True)\n",
    "high_table = {\"1st\":dictionary[top3[0][1]], \"2nd\": dictionary[top3[1][1]], \"3rd\": dictionary[top3[2][1]]}\n",
    "low_table = {\"1st\":dictionary[low3[0][1]], \"2nd\": dictionary[low3[1][1]], \"3rd\": dictionary[low3[2][1]]}\n",
    "print(\"the corresponding words:\")\n",
    "print(\"top three highest (descending)\")\n",
    "print(high_table)\n",
    "print(\"top three lowest (ascending)\")\n",
    "print(low_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Problem3\n",
    "reimlementing the perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def perceptron(training, weight, i):\n",
    "    ## initially, set w to weight\n",
    "    w = []\n",
    "    c = []\n",
    "    m = 0\n",
    "    m_cnt = 1\n",
    "    w.append(weight)\n",
    "    for idx in range(0, len(training)):\n",
    "        vi = training[idx]\n",
    "        if condition(vi, w[m], i):\n",
    "            xi = vi[:len(vi)-1]\n",
    "            yi = vi[len(vi)-1]\n",
    "            if yi == i:\n",
    "                yi = -1\n",
    "            else:\n",
    "                yi = 1\n",
    "            wi = np.add(w[m], np.multiply(xi,yi))\n",
    "            w.append(wi)\n",
    "            c.append(m_cnt)\n",
    "            m_cnt = 1\n",
    "            m = m+1\n",
    "        else:\n",
    "            m_cnt = m_cnt + 1\n",
    "    return {\"weights\":w, \"counts\":c, \"len\":m}\n",
    "        \n",
    "def condition(data, weight, i):\n",
    "    x = data[:819]\n",
    "    yi = data[819]\n",
    "    if yi == i:\n",
    "        yi = -1\n",
    "    else:\n",
    "        yi = 1\n",
    "    product = np.dot(weight, x)\n",
    "    return yi * product <= 0\n",
    "    \n",
    "def regular_predict2(data, perceptron):\n",
    "    last = perceptron['len']\n",
    "    weight = perceptron['weights'][last]\n",
    "    return predict(data, weight)\n",
    "\n",
    "def vote_predict2(data, perceptron):\n",
    "    w = perceptron['weights']\n",
    "    c = perceptron['counts']\n",
    "    length = perceptron['len']\n",
    "    result = 0\n",
    "    for i in range(0, length):\n",
    "        result = result + predict(data, w[i]) * c[i]\n",
    "    if result < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def average_predict2(data, perceptron):\n",
    "    w = perceptron['weights']\n",
    "    c = perceptron['counts']\n",
    "    length = perceptron['len']\n",
    "    sum_weights = 0\n",
    "    for i in range(0, length):\n",
    "        sum_weights = sum_weights + c[i] * w[i]\n",
    "    return predict(data, sum_weights)\n",
    "\n",
    "def error2(dataset, perceptron, flag, i):\n",
    "    err_cnt = 0\n",
    "    for data in dataset:\n",
    "        if flag == \"regular\":\n",
    "            label = regular_predict2(data, perceptron)\n",
    "        elif flag == \"vote\":\n",
    "            label = vote_predict2(data, perceptron)\n",
    "        elif flag == \"average\":\n",
    "            label = average_predict2(data, perceptron)\n",
    "        if label == -1:\n",
    "            label = i\n",
    "        else:\n",
    "            label = 0.0\n",
    "        if label != data[819]:\n",
    "            err_cnt = err_cnt+1\n",
    "    return err_cnt/len(dataset)\n",
    "\n",
    "def multi_class_predict(dataset, perceptrons, N):\n",
    "    confusion_matrix = []\n",
    "    for i in range(0, 7):\n",
    "        row = np.zeros(6)\n",
    "        confusion_matrix.append(row)\n",
    "    for data in dataset:\n",
    "        label = np.zeros(6)\n",
    "        sum = 0\n",
    "        for i in range(0, 6):\n",
    "            last_idx = perceptrons[i]['len']\n",
    "            wi = perceptrons[i]['weights'][last_idx]\n",
    "            label[i] = predict(data, wi)\n",
    "            sum += label[i]\n",
    "        if sum!=4:\n",
    "            for j in range(0, 6):\n",
    "                if label[j] == -1:\n",
    "                    confusion_matrix[6][j] += 1\n",
    "        else:\n",
    "            j = int(data[819]-1)\n",
    "            for i in range(0, 6):\n",
    "                if label[i] == -1:\n",
    "                    confusion_matrix[i][j] += 1\n",
    "    for i in range(0, 7):\n",
    "        for j in range(0, 6):\n",
    "            confusion_matrix[i][j] /= N[j]\n",
    "    return confusion_matrix\n",
    "\n",
    "def find_N(dataset):\n",
    "    N = np.zeros(6)\n",
    "    for data in dataset:\n",
    "        if data[819] == 1.0:\n",
    "            N[0] = N[0] + 1\n",
    "        elif data[819] == 2.0:\n",
    "            N[1] = N[1] + 1\n",
    "        elif data[819] == 3.0:\n",
    "            N[2] = N[2] + 1\n",
    "        elif data[819] == 4.0:\n",
    "            N[3] = N[3] + 1\n",
    "        elif data[819] == 5.0:\n",
    "            N[4] = N[4] + 1\n",
    "        else:\n",
    "            N[5] = N[5] + 1\n",
    "    return N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing the confusion matrix\n",
      "[array([0.71891892, 0.00520833, 0.03428571, 0.02173913, 0.        ,\n",
      "       0.        ]), array([0.01081081, 0.65625   , 0.03428571, 0.02717391, 0.01282051,\n",
      "       0.01851852]), array([0.        , 0.015625  , 0.37142857, 0.        , 0.        ,\n",
      "       0.02777778]), array([0.01621622, 0.00520833, 0.        , 0.69021739, 0.        ,\n",
      "       0.        ]), array([0.01621622, 0.03125   , 0.07428571, 0.00543478, 0.80128205,\n",
      "       0.12037037]), array([0.00540541, 0.01041667, 0.03428571, 0.        , 0.07051282,\n",
      "       0.49074074]), array([0.20540541, 0.32291667, 0.12571429, 0.25543478, 0.40384615,\n",
      "       0.27777778])]\n"
     ]
    }
   ],
   "source": [
    "initial_weight = np.zeros(819)\n",
    "perceptrons = []\n",
    "for i in range(0, 6):\n",
    "    perceptrons.append(perceptron(train_data, initial_weight, i+1))\n",
    "\n",
    "confusion_matrix = multi_class_predict(testing_data, perceptrons, find_N(testing_data))\n",
    "cm = np.array(confusion_matrix)\n",
    "print(\"Showing the confusion matrix\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "a) From the data in confusion matrix, the perceptron classifier has the highest accuracy for examples that belong to class 5. \n",
    "\n",
    "b) From the data in confusion matrix, the perceptron classifier has the least accuracy for examples that belong to class 2.\n",
    "\n",
    "c) The perceptron classifier most often mistakenly classifies an example in class 6 as belonging to class 5."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
